{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6bc345c",
   "metadata": {},
   "source": [
    "# Spark ML Example\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "## Table of Contents\n",
    "\n",
    " \n",
    "1. [Spark ML and Hydrosphere Mist Example: Preventive Maintenance](#1)\n",
    "2. [Business Assessment: Use Case Background](#2)\n",
    "3. [Vehicle Fleets and Analytics](#3)\t \n",
    "4. [Brake Failure Prediction](#4)\t \n",
    "5. [Brake Pad Maintenance](#5)\t \n",
    "6. [Ingest data](#6)\t \n",
    "7. [Prepare data](#7)\t \n",
    "8. [Train the model](#8)\n",
    "9. [Test the model](#9)\n",
    "10. [Expose the Model as a Web Service](#10)\n",
    "11. [Serve the Model](#11)\n",
    "12. [Complete Code](#12)\n",
    " \n",
    "\n",
    "## <a name=\"1\"></a>Spark ML and Hydrosphere Mist Example: Preventive Maintenance\t\n",
    "\n",
    "Here we provide an example in Python of how to use Hydrosphere Mist with Spark ML (machine learning library).  Mist lets us expose a model as a web service. \n",
    "\n",
    "We take this example from the field of preventive maintenance (PM) as explained below.  Below we discuss the code in depth.  But first we give a use case for why this is needed.\n",
    "\n",
    "\n",
    "## <a name=\"2\"></a>Business Assessment: Use Case Background\n",
    "PM was one of the early adopters of big data analytics and machine learning and IoT (Internet of Things) because it is so simple to conceive and implement for that use case.  Calculating when a machine needs maintenance is a problem that fits neatly into a predictive algorithm. This is because machine wear is a function of time and usage.  \n",
    "\n",
    "\n",
    "## <a name=\"3\"></a>Vehicle Fleets and Analytics\n",
    "IoT-equipped trucks send data from vehicles using a cellular or satellite signal either as a stream or in bursts.  With IoT, trucks are fit with sensors and GPS trackers that measure heat, vibration, distance travelled, speed, etc.  These sensors are attached to the engine, brakes, transmission, refrigerated trailer, etc.\n",
    "\n",
    "\n",
    "Companies gather and study this data to operate their vehicles in the safest and lowest cost manner possible.  For example, sensors on the engine can tell whether the engine has a problem.  It is the goal of PM to fix a device before it breaks as waiting until it breaks is expensive as the engine, brake assembly, or drive train can be destroyed and the vehicle taken out of service for a longer period of time than if it is properly maintained\n",
    "\n",
    "\n",
    "## <a name=\"4\"></a>Brake Failure Prediction\n",
    "A heavy truck with 18 wheels has a unique preventive maintenance problem to solve, and that is knowing when to change brakes.  Trucks needs to know when to replace their brakes so that they do not have an accident or destroy the brake rotor, which is the metal part of the assembly.  If they wait too long the brake pad will destroy the rotor as metal rubs up against metal.   \n",
    "\n",
    "\n",
    "The driver cannot be expected to check every brake every time they stop.  And if the company just changes brakes based on some preset schedule then they are wasting money, because they might be changing them too often. So it is preferred to write some mathematical or statistical model to predict when brakes should be changed.  \n",
    "\n",
    "\n",
    "## <a name=\"5\"></a>Brake Pad Maintenance\n",
    "Brake pads are metal shavings held together by a resin. The brake applies pressure to the pad to force it down on the rotor, which is a metal disk connected to a truckâ€™s axles.  The pad is designed to wear out over time.  It has to be softer than the rotor, so that it does not damage the rotor.   When the brake pad wears down, heat will go up because there is more friction.  And the further a vehicle has been driven the more its brakes will have worn down.\n",
    "\n",
    "\n",
    "We contacted an engineer from Volvo and he verified that this model would work as a teaching exercise as it seems reasonable to correlate heat and distance driven with wear.  To get a more accurate model we would have to use something like data from the [IDA Industrial Challenge](https://ida2016.blogs.dsv.su.se/?page_id=1387), which was a competition made by Scana trucking company.\n",
    "\n",
    "\n",
    "There are lots of factors that impact brake wear.  For example, brakes will wear out faster for vehicles that drive down steep hills.   \n",
    "\n",
    "\n",
    "We do not have any actual sample data.  So we generated some sample date using this rough model:\n",
    "\n",
    "\n",
    "`z = wear_rate = (0.003 * heat) + (0.004 * kilometers)-78`\n",
    "\n",
    "\n",
    "This shows whether the brakes are worn out given the kilometers driven and the maximum heat generated during gathering the sample.\n",
    "\n",
    "\n",
    "We plug that value into the logistic probability function:\n",
    "\n",
    "\n",
    "`pr = 1 / (1 + e**-z)`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The binary logistic model generates a binary output, which we will call worn. So if pr > 50% then worn = 1. Otherwise worn = 0. If worn = 1 then it is time to change brake pads.\n",
    "\n",
    "\n",
    "\n",
    "## <a name=\"6\"></a>Ingest Data\n",
    "  \n",
    "For this tutorial, we write two Python programs.  The code for both is located at the bottom of this page.\n",
    "\n",
    "1. ***brakeTrain.py** to ingest and prepare the data, train the model, and calculate its accuracy.  \n",
    "2. **brakePredict.py** uses Mist to expose the model as a web service to return a prediction as to whether the brake is worn. \n",
    "\n",
    "First we look at brakeTrain.py.  We copy that code into pyspark and run it there.  The pyspark interactive Spark shell gives us a SparkContext without having to code that.  \n",
    "\n",
    "The sample data is [here](https://raw.githubusercontent.com/werowe/mist_preventive_maintenance_ml/master/brakedata.csv).  Below is the first line.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>worn</td><td>km</td><td>heat</td><td>z</td><td>pr</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>1</td><td>20,000</td><td>240</td><td>2.72</td><td>0.938197</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "We read this data into a Pandas data frame and then select only the first three columns: whether the brake is worn, kilometers, brake rotor heat.\n",
    "\n",
    "```\n",
    "df = pd.read_csv('/home/walker/hydrosphere/brakedata.csv', sep= ',')\n",
    " \n",
    "brakeData =  df.ix[:,0:3]\n",
    "```\n",
    "\n",
    "## <a name=\"7\"></a>Prepare Data\n",
    "The Spark ML LogisticRegressionWithLBFGS algorithm requires that we put the data into an iterable object of Labels and Points.  So we have an array of LabeledPoint objects.  The Label is the result of logistic regression.  In this case it indicates whether the brake is worn (1) or not (0).  The Points are the kilometers (km) and temperature (heat).\n",
    "\n",
    "\n",
    "```\n",
    "a = [] \n",
    "\n",
    "def parsePoint(w,k,h):\n",
    "    return LabeledPoint(worn, [km, heat])\n",
    "\n",
    "\n",
    "for row in brakeData.itertuples():\n",
    "\tworn = getattr(row, 'worn')\n",
    "\tkm = locale.atof(getattr(row, 'km'))\n",
    "\theat = getattr(row,'heat')\n",
    "\tlp = parsePoint (worn, km, heat)\n",
    "\ta.append(lp)\n",
    "```\n",
    "\n",
    "\n",
    "## <a name=\"8\"></a>Train the Model\n",
    "Now we train the model by passing that array into LogisticRegressionWithLBFGS.train. Then we save the model to disk so that the web service can use it.\n",
    "\n",
    "Once the model lrm is created, we can call the lrm.predict() method.\n",
    "\n",
    "```\n",
    "lrm = LogisticRegressionWithLBFGS.train(sc.parallelize(a))\n",
    "lrm.save(sc, \"/tmp/brakeModel\")\n",
    "```\n",
    "\n",
    "\n",
    "## <a name=\"9\"></a>Test the Model\n",
    "To test the model we take the training data and then run the prediction over each data point in the sample data.  We then count how many correct predictions there are and divide that by the sample size.  That calculates the model accuracy.\n",
    "\n",
    "```\n",
    "p = sc.parallelize(a)\n",
    "\n",
    "valuesAndPreds = p.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    "\n",
    "\n",
    "accurate = 1 - valuesAndPreds.map(lambda (v, p): math.fabs(v-p)).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "```\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## <a name=\"12\"></a>Complete Code\n",
    "\n",
    "Here is the code:\n",
    "\n",
    "\n",
    "*BrakeTrain.py*\n",
    "\n",
    "```\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "import locale\n",
    "import math\n",
    "locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' ) \n",
    "\n",
    "df = pd.read_csv('/home/walker/hydrosphere/brakedata.csv', sep= ',')\n",
    " \n",
    "brakeData =  df.ix[:,0:3]\n",
    "\n",
    "a = [] \n",
    "\n",
    "\n",
    "def parsePoint(w,k,h):\n",
    "    return LabeledPoint(worn, [km, heat])\n",
    "\n",
    "for row in brakeData.itertuples():\n",
    "\tworn = getattr(row, 'worn')\n",
    "\tkm = locale.atof(getattr(row, 'km'))\n",
    "\theat = getattr(row,'heat')\n",
    "\tlp = parsePoint (worn, km, heat)\n",
    "\ta.append(lp)\n",
    "\n",
    "\n",
    "lrm = LogisticRegressionWithLBFGS.train(sc.parallelize(a))\n",
    "\n",
    "lrm.save(sc, \"/tmp/brakeModel\")\n",
    "\n",
    "p = sc.parallelize(a)\n",
    "\n",
    "valuesAndPreds = p.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    "accurate = 1 - valuesAndPreds.map(lambda (v, p): math.fabs(v-p)).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "\n",
    "```\n",
    "*BrakePredict.py*\n",
    "\n",
    "```\n",
    "\n",
    "from mist.mist_job import MistJob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy import array\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionModel\n",
    "\n",
    "class Predict(MistJob):\n",
    " \n",
    "    def do_stuff(self, parameters):\n",
    "        val = parameters.values()\n",
    "        list = val.head()\n",
    "        size = list.size()\n",
    "        pylist = []\n",
    "        count = 0\n",
    "        while count < size:\n",
    "            pylist.append(list.head())\n",
    "            count = count + 1\n",
    "            list = list.tail()\n",
    "\n",
    "\n",
    "        heat = pylist[0]\n",
    "        km = pylist[1]\n",
    "        lrm = LogisticRegressionModel.load(self.context, \"/tmp/brakeModel\")\n",
    "        worn = lrm.predict([km,heat])\n",
    "        return (\"brake is worn=\", worn)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db43c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/30 16:41:25 WARN Utils: Your hostname, Walkers-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.88 instead (on interface en0)\n",
      "24/04/30 16:41:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/30 16:41:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example-app\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9eefda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/30 16:41:50 WARN Instrumentation: [73da3f66] Initial coefficients will be ignored! Its dimensions (1, 2) did not match the expected size (1, 2)\n",
      "24/04/30 16:41:51 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/04/30 16:41:51 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# brake train\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "import locale\n",
    "import math\n",
    "locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' ) \n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/werowe/mist_preventive_maintenance_ml/master/brakedata.csv', sep= ',')\n",
    " \n",
    "brakeData =  df.iloc[:,0:3]\n",
    "\n",
    "a = [] \n",
    "\n",
    "\n",
    "def parsePoint(w,k,h):\n",
    "    return LabeledPoint(worn, [km, heat])\n",
    "\n",
    "for row in brakeData.itertuples():\n",
    "\tworn = getattr(row, 'worn')\n",
    "\tkm = locale.atof(getattr(row, 'km'))\n",
    "\theat = getattr(row,'heat')\n",
    "\tlp = parsePoint (worn, km, heat)\n",
    "\ta.append(lp)\n",
    "\n",
    "\n",
    "lrm = LogisticRegressionWithLBFGS.train(sc.parallelize(a))\n",
    "\n",
    "#lrm.save(sc, \"/tmp/brakeModel\")\n",
    "\n",
    "p = sc.parallelize(a)\n",
    "\n",
    "valuesAndPreds = p.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    " \n",
    "\n",
    "accurate = 1 - valuesAndPreds.map(lambda vp: math.fabs(vp[0] - vp[1])).reduce(lambda x, y: x + y) / valuesAndPreds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755c3a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1)\n",
      "(0.0, 0)\n",
      "(1.0, 1)\n",
      "(0.0, 0)\n",
      "(1.0, 1)\n",
      "(1.0, 1)\n",
      "(1.0, 1)\n",
      "(0.0, 1)\n",
      "(0.0, 0)\n",
      "(0.0, 0)\n",
      "(1.0, 1)\n",
      "(1.0, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for value in valuesAndPreds.collect():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ad362",
   "metadata": {},
   "source": [
    "this part we need to modify to run on spark it was designed to run on mist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1a8f9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worn</th>\n",
       "      <th>km</th>\n",
       "      <th>heat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20,000</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5,000</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>50,000</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8,000</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>23,790</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>24,644</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>29,934</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>14,045</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8,000</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9,855</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>24,633</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>20,753</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    worn      km  heat\n",
       "0      1  20,000   240\n",
       "1      0   5,000    98\n",
       "2      1  50,000   140\n",
       "3      0   8,000   260\n",
       "4      1  23,790   225\n",
       "5      1  24,644   245\n",
       "6      1  29,934   195\n",
       "7      0  14,045   153\n",
       "8      0   8,000   222\n",
       "9      0   9,855   149\n",
       "10     1  24,633   271\n",
       "11     1  20,753   209"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brakeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4729bfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 9 heat 149 km 9855\n",
      "brake is worn= 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    " \n",
    "i=np.random.randint(0,len(brakeData))\n",
    "km = brakeData.loc[i,['km']]\n",
    "heat = brakeData.loc[i,['heat']].values[0]\n",
    "        \n",
    " \n",
    "km=int(re.sub(r'[^\\d]', '', km.values[0]))\n",
    "\n",
    "print(\"row %i heat %i km %i\" % (i,heat,km))\n",
    "\n",
    "#lrm = LogisticRegressionModel.load(self.context, \"/tmp/brakeModel\")\n",
    "worn = lrm.predict([km,heat])\n",
    "print(\"brake is worn=\", worn)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb93d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3621875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd9565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
