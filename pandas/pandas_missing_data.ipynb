{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuYhp1Q6dU4OLOsKnZl0az",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/werowe/HypatiaAcademy/blob/master/pandas/pandas_missing_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Clean Up Pandas Data\n",
        "\n",
        "Here we should how to clean up Pandas data, in particular what do with about missing data, as well as what to do with invalid data.\n",
        "\n",
        "Consider a survey.  If you send people a survey you cannot control in all cases what questions they will answer.  And you cannot anticipate what data they might put that is invalid.  For example, they might leave off some data.  Or they might enter a number in a question that is only supposed to be text.\n",
        "\n",
        "So here we show you how to :\n",
        "\n",
        "* generate some random data that is purposefully not clean\n",
        "* drop duplicate rows\n",
        "* get rid of rows that have missing values\n",
        "* convert missing values to something else, like a fixed value of the average of all the other values in the colummn\n",
        "* delete outliers, which are obvious typos.  For example, here we enter some salaries as 1 million while everyone else is around 100,000.  So that's most likely a mistake (since these are employees and not company owners or the CEO).\n",
        "* apply a custom function to every row to do whatever special checking you want\n",
        "* check for missing values\n",
        "* show different ways to check for numbers or strings and how to convert those when they are of the wrong type"
      ],
      "metadata": {
        "id": "QqdCB1yyrZPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bad Data\n",
        "\n",
        "Below we create some data and purposely add some bad data.  What do we do with this data?  Do we fix it? We we erase it?  Do we drop entire rows?  If this was a survey of 100 question you would not want to delete the rows because almost every person will either put bad data or not answer all questions.\n",
        "\n",
        "In this data we have:\n",
        "\n",
        "1. blank data in numeric columns\n",
        "2. NaN (not a number) data in numeric columns\n",
        "3. blank values in text columns\n",
        "4. numbers that are multiple standard deviation away from the other answers, suggesting a type\n",
        "5. Number in a Yes-No column\n",
        "\n",
        "We will show how to clean up each.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C2no6OArb7Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "\n",
        "def makedata():\n",
        "  mean=10000\n",
        "  std=25\n",
        "\n",
        "  # this code creates random data.  It adds invalid and missing values to give us data to work with.\n",
        "\n",
        "  cols = [(\"name\", str), (\"education\", str),\n",
        "     (\"age\", np.int8), (\"city\",str), (\"id\", np.int8), (\"email\", str), (\"salary\", np.int8),\n",
        "        (\"citizen\", [\"Y\", \"N\"])]\n",
        "\n",
        "  words = [np.NaN, \"\", \"abc\", \"def\", \"ghi\", \"jkl\", \"mno\", \"pqr\"]\n",
        "\n",
        "  records = []\n",
        "\n",
        "  for i in range(20):\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    for c in cols:\n",
        "\n",
        "      if c[1] == np.int8:\n",
        "        if random.randint(0,5)==5:\n",
        "            data[c[0]] = np.NaN\n",
        "        else:\n",
        "            data[c[0]] = abs(int(random.gauss(mean, std)))\n",
        "\n",
        "      if c[0] == \"citizen\":\n",
        "        if random.randint(0,5)==5:\n",
        "            data[c[0]] = random.randint(0,10)\n",
        "        else:\n",
        "            data[c[0]] =c[1][random.randint(0,1)]\n",
        "\n",
        "      if c[1] == str and c[0] != \"citizen\":\n",
        "        data[c[0]] = words[random.randint(0,len(words)-1)]\n",
        "\n",
        "      if (c[0] == \"salary\") & (random.randint(0,5)==0):\n",
        "            data[c[0]] = 1000000\n",
        "\n",
        "      if (c[0] == \"age\"):\n",
        "          data[c[0]] = random.randint(20,25)\n",
        "\n",
        "    records.append(data)\n",
        "\n",
        "  df=pd.DataFrame(records)\n",
        "\n",
        "  return df\n",
        "\n",
        "df = makedata()\n",
        "df\n"
      ],
      "metadata": {
        "id": "qGkqj9VuN_py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.randint(0,10)"
      ],
      "metadata": {
        "id": "aaEtv8e_eVtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if column in series is empty\n",
        "\n",
        "df['name'].isnull()\n"
      ],
      "metadata": {
        "id": "RtxOSt-xOoNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we check if\n",
        "\n",
        "(df.isna() | (df == 0) | (df == '') |df.isnull())\n",
        ""
      ],
      "metadata": {
        "id": "BVMWvj1parF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.NaN == None"
      ],
      "metadata": {
        "id": "JbBQQ0dtbjR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['salary']"
      ],
      "metadata": {
        "id": "FAW2mFmVfv4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw from mean()\n",
        "# we can use the mean() function on a series.  A series is one column.\n",
        "# Then we can replace blank values with the mean.  This is logical.\n",
        "\n",
        "sMean=df['salary'].mean()\n",
        "\n",
        "df['salary'] = df['salary'].fillna(sMean)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "tPTExxjEY3eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yes, No columns cannot contain numbers\n",
        "# NaN is OK as we can get rid of it in a second step plus certain functions like mean()\n",
        "# will ignore it.  coerce means convert to NaN on error\n",
        "\n",
        "df['citizen'] = df['citizen'].apply(lambda x: x if x in ['Y', 'N'] else \"\")\n",
        "\n",
        "df['citizen']"
      ],
      "metadata": {
        "id": "43mFAjg7Y1I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop outliers, too many standard deviations away\n",
        "# if the income - mean > 2 std the replace then drop the row\n",
        "# remeber to use inplace=True\n",
        "\n",
        "\n",
        "mean = df['salary'].mean()\n",
        "std = df['salary'].std()\n",
        "\n",
        "# Define threshold for outliers (e.g., values more than 2 standard deviations away from the mean)\n",
        "threshold = 2\n",
        "\n",
        "df.drop(df.loc[(df['salary'] - mean) > 2 * std].index, inplace=True)\n",
        "df\n",
        "\n"
      ],
      "metadata": {
        "id": "iydjkpnHZhaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop all numbers in Yes/No answer\n",
        "\n",
        "df['citizen'] = df['citizen'].apply(lambda x: x if isinstance(x,str) else np.NaN)\n",
        "df['citizen']\n"
      ],
      "metadata": {
        "id": "QhVP030uJBXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here is how to drop all rows that have any NaN values in any column.\n",
        "# we will leave off inplace=True so that we don't delete all the data that we need for this lesson.\n",
        "# remember that if you don't put inplace=True and you have not assigned the df.somefunction() to\n",
        "# some value then you have effectively done nothing as nothing has changed\n",
        "\n",
        "df.dropna(how='any')\n",
        "df"
      ],
      "metadata": {
        "id": "67AKYyKgRg8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here run a function on a Pandas series, which is a single column.  But since we are\n",
        "# sending a single row-column combination we can work with it as we would with any\n",
        "# Python primitive (meaning built-in type.  Pandas and Numpy are extension of Python into new types.)\n",
        "# In the next example we show how to work with an entire row, where we have all columns we can work with\n",
        "\n",
        "\n",
        "def toUpper(s):\n",
        "    if isinstance(s,str):\n",
        "      return s.upper()\n",
        "\n",
        "\n",
        "df['city']=df['city'].apply(toUpper)\n",
        "df"
      ],
      "metadata": {
        "id": "WrDMjVKPar5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# axis = 1 means row\n",
        "# axis = 0 means column\n",
        "\n",
        "# the important point to note there is we send the entire row in as a paramters. thus all the columns\n",
        "# are available to use.  remember to send back the entire row after you have updated any of the columns.\n",
        "\n",
        "def wholeRow(row):\n",
        "  if isinstance(row['city'],str):\n",
        "     row['city'] = row['city'].lower()\n",
        "     return row\n",
        "\n",
        "\n",
        "df=df.apply(wholeRow, axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "TRuXKcGzbfbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eliminate Duplicates\n",
        "\n",
        "Here we show how to get rid of duplicate rows.  \n"
      ],
      "metadata": {
        "id": "c6mV5XPJt0ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"a\" : [1,2,3,3,3,3,5,6,7,7,7,7]\n",
        "\n",
        "})\n",
        "\n",
        "df.groupby('a')['a'].count()\n"
      ],
      "metadata": {
        "id": "Sql2zGRMfkSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.value_counts()"
      ],
      "metadata": {
        "id": "mcmHQuShhRAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.groupby('a')['a'].count()"
      ],
      "metadata": {
        "id": "_uJG1ZIhiv9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['a'].value_counts()"
      ],
      "metadata": {
        "id": "3ssqbo9gkYvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = makedata()\n",
        "\n",
        "df.groupby('age')['age'].count()"
      ],
      "metadata": {
        "id": "Mqclf-g1ksIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep='first' Mark duplicates as True except for the first occurrence\n",
        "\n",
        "df['duplicate'] = df.duplicated(subset=['age'], keep='first')\n",
        "\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "nNSP9NOCjbjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop those where duplicate is true.  Notice the gap in index values show which rows were dropped\n",
        "\n",
        "\n",
        "df[df['duplicate'] == True]"
      ],
      "metadata": {
        "id": "ioVBdatrm6Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "onSf7KAul0wv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}